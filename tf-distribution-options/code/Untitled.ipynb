{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-441707470931/data/tf-distribution-options-index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(13)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_def import HEIGHT, WIDTH, DEPTH, NUM_CLASSES\n",
    "from utilities import _train_preprocess_fn\n",
    "\n",
    "def _dataset_parser(value):\n",
    "\n",
    "    featdef = {\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64)\n",
    "    #    'index': tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    example = tf.parse_single_example(value, featdef)\n",
    "    image = tf.decode_raw(example['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    #index = tf.cast(example['index'], tf.int32)\n",
    "    image = _train_preprocess_fn(image)\n",
    "    return image, tf.one_hot(label, NUM_CLASSES)#, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(channel, path):\n",
    "    if channel == 'train':\n",
    "        records = [48,62,51,15,91,95,88,11,22,33,3,77,55,26,73,59,40,80,19,99,44,7,66,37,84]\n",
    "        filenames = ['../data/train/train_{}.tfrecords'.format(num) for num in records]\n",
    "    else:\n",
    "        filenames = utilities._get_filenames(channel, path)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(10)\n",
    "    dataset = dataset.map(_dataset_parser, num_parallel_calls=10)\n",
    "    dataset = dataset.batch(128, drop_remainder=True)\n",
    "    if channel == 'train':\n",
    "        # Ensure that the capacity is sufficiently large to provide good random\n",
    "        # shuffling.\n",
    "        buffer_size = int(50000 * 0.4) + 3 * 128\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 03:19:10.765670 139964965705536 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from model_def import get_model\n",
    "model = get_model(0.001, 2e-4, 'adam', 0.9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [6,41,2,0,30,63,38,27,74,96,78,92,16,67,70,81,56,89,34,45,49,52,12,23,85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 03:19:12.531327 139964965705536 deprecation_wrapper.py:119] From /home/ec2-user/SageMaker/amazon-sagemaker-script-mode/tf-distribution-options/code/utilities.py:25: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\n",
      "W0822 03:19:12.543909 139964965705536 deprecation_wrapper.py:119] From /home/ec2-user/SageMaker/amazon-sagemaker-script-mode/tf-distribution-options/code/utilities.py:28: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:10: UserWarning: Seed 13 from outer graph might be getting used by function Dataset_map__dataset_parser, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.\n",
      "W0822 03:19:12.589290 139964965705536 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_dataset('train', '../data/train/')\n",
    "val_dataset = get_dataset('validation', '../data/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - 322s 4s/step - loss: 2.2249 - acc: 0.2216 - val_loss: 1.9895 - val_acc: 0.2470\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 1.8061 - acc: 0.3197 - val_loss: 2.2591 - val_acc: 0.2065\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 44s 569ms/step - loss: 1.6929 - acc: 0.3653 - val_loss: 1.7996 - val_acc: 0.3477\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 40s 518ms/step - loss: 1.6027 - acc: 0.4021 - val_loss: 1.9691 - val_acc: 0.3483\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 43s 554ms/step - loss: 1.5229 - acc: 0.4345 - val_loss: 1.9151 - val_acc: 0.3329\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 42s 539ms/step - loss: 1.4728 - acc: 0.4669 - val_loss: 1.9127 - val_acc: 0.3395\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 47s 600ms/step - loss: 1.3946 - acc: 0.4961 - val_loss: 1.3105 - val_acc: 0.5157\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 42s 535ms/step - loss: 1.3345 - acc: 0.5180 - val_loss: 1.6484 - val_acc: 0.4274\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 42s 534ms/step - loss: 1.2987 - acc: 0.5323 - val_loss: 1.3039 - val_acc: 0.5220\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 43s 556ms/step - loss: 1.2486 - acc: 0.5534 - val_loss: 1.3845 - val_acc: 0.5110\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 41s 530ms/step - loss: 1.2148 - acc: 0.5627 - val_loss: 1.3924 - val_acc: 0.4978\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 38s 481ms/step - loss: 1.1853 - acc: 0.5838 - val_loss: 1.7470 - val_acc: 0.4314\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 41s 527ms/step - loss: 1.1438 - acc: 0.5902 - val_loss: 1.2507 - val_acc: 0.5569\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 1.0981 - acc: 0.6087 - val_loss: 1.2607 - val_acc: 0.5523\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 42s 541ms/step - loss: 1.1008 - acc: 0.6093 - val_loss: 1.0744 - val_acc: 0.6193\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 42s 533ms/step - loss: 1.0599 - acc: 0.6246 - val_loss: 1.0854 - val_acc: 0.6077\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 42s 538ms/step - loss: 1.0341 - acc: 0.6367 - val_loss: 1.0285 - val_acc: 0.6386\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 40s 515ms/step - loss: 1.0473 - acc: 0.6328 - val_loss: 1.0461 - val_acc: 0.6260\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 43s 556ms/step - loss: 0.9806 - acc: 0.6528 - val_loss: 1.1238 - val_acc: 0.6033\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 43s 553ms/step - loss: 0.9872 - acc: 0.6452 - val_loss: 1.0331 - val_acc: 0.6334\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.9397 - acc: 0.6655 - val_loss: 1.1361 - val_acc: 0.6050\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 41s 532ms/step - loss: 0.9539 - acc: 0.6641 - val_loss: 1.0101 - val_acc: 0.6389\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 42s 543ms/step - loss: 0.9084 - acc: 0.6832 - val_loss: 1.5706 - val_acc: 0.5107\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 42s 535ms/step - loss: 0.9368 - acc: 0.6664 - val_loss: 1.1513 - val_acc: 0.6052\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 40s 510ms/step - loss: 0.8932 - acc: 0.6856 - val_loss: 1.2907 - val_acc: 0.5871\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 46s 590ms/step - loss: 0.8875 - acc: 0.6846 - val_loss: 0.9117 - val_acc: 0.6794\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 41s 526ms/step - loss: 0.8791 - acc: 0.6891 - val_loss: 0.9179 - val_acc: 0.6702\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 40s 518ms/step - loss: 0.8416 - acc: 0.7044 - val_loss: 1.1320 - val_acc: 0.6230\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 42s 545ms/step - loss: 0.8135 - acc: 0.7181 - val_loss: 1.1151 - val_acc: 0.6277\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 44s 568ms/step - loss: 0.8524 - acc: 0.6976 - val_loss: 0.8934 - val_acc: 0.6820\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 40s 513ms/step - loss: 0.7978 - acc: 0.7213 - val_loss: 0.9693 - val_acc: 0.6641\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 41s 521ms/step - loss: 0.8267 - acc: 0.7099 - val_loss: 0.8594 - val_acc: 0.6978\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 42s 534ms/step - loss: 0.7973 - acc: 0.7190 - val_loss: 0.8030 - val_acc: 0.7171\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 41s 526ms/step - loss: 0.7877 - acc: 0.7236 - val_loss: 0.7810 - val_acc: 0.7305\n",
      "Epoch 35/100\n",
      "78/78 [==============================] - 41s 530ms/step - loss: 0.7734 - acc: 0.7274 - val_loss: 0.7824 - val_acc: 0.7239\n",
      "Epoch 36/100\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.7739 - acc: 0.7254 - val_loss: 0.8798 - val_acc: 0.6974\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - 30s 390ms/step - loss: 0.7458 - acc: 0.7359 - val_loss: 0.8617 - val_acc: 0.7037\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - 43s 553ms/step - loss: 0.7462 - acc: 0.7419 - val_loss: 0.8435 - val_acc: 0.7082\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - 41s 530ms/step - loss: 0.7339 - acc: 0.7385 - val_loss: 0.8087 - val_acc: 0.7214\n",
      "Epoch 40/100\n",
      "78/78 [==============================] - 37s 474ms/step - loss: 0.7333 - acc: 0.7441 - val_loss: 0.8112 - val_acc: 0.7232\n",
      "Epoch 41/100\n",
      "78/78 [==============================] - 35s 452ms/step - loss: 0.7291 - acc: 0.7503 - val_loss: 0.8585 - val_acc: 0.7077\n",
      "Epoch 42/100\n",
      "78/78 [==============================] - 38s 493ms/step - loss: 0.6991 - acc: 0.7578 - val_loss: 0.9209 - val_acc: 0.6895\n",
      "Epoch 43/100\n",
      "78/78 [==============================] - 43s 547ms/step - loss: 0.7073 - acc: 0.7523 - val_loss: 1.0998 - val_acc: 0.6376\n",
      "Epoch 44/100\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 0.7089 - acc: 0.7510 - val_loss: 0.9078 - val_acc: 0.6879\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - 40s 518ms/step - loss: 0.6957 - acc: 0.7611 - val_loss: 0.7475 - val_acc: 0.7463\n",
      "Epoch 46/100\n",
      "78/78 [==============================] - 37s 474ms/step - loss: 0.6857 - acc: 0.7596 - val_loss: 0.7829 - val_acc: 0.7321\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 0.6736 - acc: 0.7634 - val_loss: 0.7622 - val_acc: 0.7371\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - 39s 495ms/step - loss: 0.6487 - acc: 0.7738 - val_loss: 1.0605 - val_acc: 0.6632\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6447 - acc: 0.7734 - val_loss: 0.8821 - val_acc: 0.7152\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - 38s 490ms/step - loss: 0.6186 - acc: 0.7835 - val_loss: 0.7910 - val_acc: 0.7369\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 0.6301 - acc: 0.7798 - val_loss: 0.7774 - val_acc: 0.7360\n",
      "Epoch 52/100\n",
      "78/78 [==============================] - 42s 543ms/step - loss: 0.6307 - acc: 0.7818 - val_loss: 0.9753 - val_acc: 0.6813\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - 46s 583ms/step - loss: 0.6384 - acc: 0.7742 - val_loss: 0.7731 - val_acc: 0.7386\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.6245 - acc: 0.7780 - val_loss: 0.8636 - val_acc: 0.7193\n",
      "Epoch 55/100\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6215 - acc: 0.7810 - val_loss: 0.9351 - val_acc: 0.7074\n",
      "Epoch 56/100\n",
      "78/78 [==============================] - 41s 524ms/step - loss: 0.6139 - acc: 0.7866 - val_loss: 0.7615 - val_acc: 0.7440\n",
      "Epoch 57/100\n",
      "78/78 [==============================] - 43s 547ms/step - loss: 0.5988 - acc: 0.7901 - val_loss: 0.7869 - val_acc: 0.7324\n",
      "Epoch 58/100\n",
      "78/78 [==============================] - 44s 562ms/step - loss: 0.6027 - acc: 0.7914 - val_loss: 0.7761 - val_acc: 0.7387\n",
      "Epoch 59/100\n",
      "78/78 [==============================] - 38s 493ms/step - loss: 0.5838 - acc: 0.7970 - val_loss: 0.7200 - val_acc: 0.7578\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - 43s 549ms/step - loss: 0.5733 - acc: 0.7973 - val_loss: 0.8348 - val_acc: 0.7230\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - 42s 536ms/step - loss: 0.5742 - acc: 0.8007 - val_loss: 0.7496 - val_acc: 0.7453\n",
      "Epoch 62/100\n",
      "78/78 [==============================] - 43s 553ms/step - loss: 0.5698 - acc: 0.8022 - val_loss: 0.7630 - val_acc: 0.7464\n",
      "Epoch 63/100\n",
      "78/78 [==============================] - 44s 568ms/step - loss: 0.5690 - acc: 0.8036 - val_loss: 0.6853 - val_acc: 0.7688\n",
      "Epoch 64/100\n",
      "78/78 [==============================] - 42s 543ms/step - loss: 0.5568 - acc: 0.8046 - val_loss: 0.8249 - val_acc: 0.7310\n",
      "Epoch 65/100\n",
      "78/78 [==============================] - 41s 528ms/step - loss: 0.5522 - acc: 0.8073 - val_loss: 0.7301 - val_acc: 0.7553\n",
      "Epoch 66/100\n",
      "78/78 [==============================] - 37s 479ms/step - loss: 0.5638 - acc: 0.8043 - val_loss: 0.7027 - val_acc: 0.7645\n",
      "Epoch 67/100\n",
      "78/78 [==============================] - 45s 582ms/step - loss: 0.5497 - acc: 0.8089 - val_loss: 0.7062 - val_acc: 0.7670\n",
      "Epoch 68/100\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.5472 - acc: 0.8080 - val_loss: 0.7455 - val_acc: 0.7497\n",
      "Epoch 69/100\n",
      "78/78 [==============================] - 42s 541ms/step - loss: 0.5356 - acc: 0.8073 - val_loss: 0.7789 - val_acc: 0.7505\n",
      "Epoch 70/100\n",
      "78/78 [==============================] - 45s 579ms/step - loss: 0.5136 - acc: 0.8253 - val_loss: 0.7946 - val_acc: 0.7508\n",
      "Epoch 71/100\n",
      "78/78 [==============================] - 41s 524ms/step - loss: 0.5371 - acc: 0.8137 - val_loss: 0.6640 - val_acc: 0.7743\n",
      "Epoch 72/100\n",
      "78/78 [==============================] - 37s 478ms/step - loss: 0.5255 - acc: 0.8167 - val_loss: 0.6992 - val_acc: 0.7645\n",
      "Epoch 73/100\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.5237 - acc: 0.8230 - val_loss: 0.7939 - val_acc: 0.7442\n",
      "Epoch 74/100\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.5134 - acc: 0.8199 - val_loss: 0.6838 - val_acc: 0.7660\n",
      "Epoch 75/100\n",
      "78/78 [==============================] - 41s 527ms/step - loss: 0.5154 - acc: 0.8180 - val_loss: 0.7032 - val_acc: 0.7652\n",
      "Epoch 76/100\n",
      "78/78 [==============================] - 40s 507ms/step - loss: 0.5050 - acc: 0.8239 - val_loss: 0.7238 - val_acc: 0.7703\n",
      "Epoch 77/100\n",
      "78/78 [==============================] - 38s 485ms/step - loss: 0.5043 - acc: 0.8248 - val_loss: 0.7225 - val_acc: 0.7634\n",
      "Epoch 78/100\n",
      "78/78 [==============================] - 41s 521ms/step - loss: 0.4966 - acc: 0.8298 - val_loss: 0.6529 - val_acc: 0.7866\n",
      "Epoch 79/100\n",
      "78/78 [==============================] - 43s 549ms/step - loss: 0.5104 - acc: 0.8206 - val_loss: 0.7124 - val_acc: 0.7681\n",
      "Epoch 80/100\n",
      "78/78 [==============================] - 45s 573ms/step - loss: 0.4949 - acc: 0.8235 - val_loss: 0.6789 - val_acc: 0.7806\n",
      "Epoch 81/100\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.4737 - acc: 0.8366 - val_loss: 0.7031 - val_acc: 0.7691\n",
      "Epoch 82/100\n",
      "78/78 [==============================] - 42s 535ms/step - loss: 0.4989 - acc: 0.8239 - val_loss: 0.7290 - val_acc: 0.7651\n",
      "Epoch 83/100\n",
      "78/78 [==============================] - 39s 496ms/step - loss: 0.4721 - acc: 0.8351 - val_loss: 0.8481 - val_acc: 0.7350\n",
      "Epoch 84/100\n",
      "78/78 [==============================] - 43s 552ms/step - loss: 0.4895 - acc: 0.8258 - val_loss: 0.7779 - val_acc: 0.7433\n",
      "Epoch 85/100\n",
      "78/78 [==============================] - 42s 536ms/step - loss: 0.4883 - acc: 0.8311 - val_loss: 0.7395 - val_acc: 0.7611\n",
      "Epoch 86/100\n",
      "78/78 [==============================] - 36s 466ms/step - loss: 0.4707 - acc: 0.8379 - val_loss: 0.7461 - val_acc: 0.7616\n",
      "Epoch 87/100\n",
      "78/78 [==============================] - 40s 512ms/step - loss: 0.4684 - acc: 0.8339 - val_loss: 0.6963 - val_acc: 0.7738\n",
      "Epoch 88/100\n",
      "78/78 [==============================] - 44s 565ms/step - loss: 0.4709 - acc: 0.8374 - val_loss: 0.6735 - val_acc: 0.7824\n",
      "Epoch 89/100\n",
      "78/78 [==============================] - 42s 540ms/step - loss: 0.4728 - acc: 0.8296 - val_loss: 0.6917 - val_acc: 0.7719\n",
      "Epoch 90/100\n",
      "78/78 [==============================] - 42s 538ms/step - loss: 0.4469 - acc: 0.8431 - val_loss: 0.7485 - val_acc: 0.7643\n",
      "Epoch 91/100\n",
      "78/78 [==============================] - 40s 507ms/step - loss: 0.4612 - acc: 0.8427 - val_loss: 0.6601 - val_acc: 0.7801\n",
      "Epoch 92/100\n",
      "78/78 [==============================] - 42s 534ms/step - loss: 0.4621 - acc: 0.8384 - val_loss: 0.6637 - val_acc: 0.7819\n",
      "Epoch 93/100\n",
      "78/78 [==============================] - 40s 511ms/step - loss: 0.4508 - acc: 0.8430 - val_loss: 0.7355 - val_acc: 0.7690\n",
      "Epoch 94/100\n",
      "78/78 [==============================] - 36s 464ms/step - loss: 0.4488 - acc: 0.8379 - val_loss: 0.6998 - val_acc: 0.7731\n",
      "Epoch 95/100\n",
      "78/78 [==============================] - 38s 485ms/step - loss: 0.4226 - acc: 0.8540 - val_loss: 0.7109 - val_acc: 0.7775\n",
      "Epoch 96/100\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 0.4484 - acc: 0.8409 - val_loss: 0.8047 - val_acc: 0.7480\n",
      "Epoch 97/100\n",
      "78/78 [==============================] - 36s 467ms/step - loss: 0.4260 - acc: 0.8469 - val_loss: 0.7525 - val_acc: 0.7643\n",
      "Epoch 98/100\n",
      "78/78 [==============================] - 35s 447ms/step - loss: 0.4376 - acc: 0.8461 - val_loss: 0.7244 - val_acc: 0.7679\n",
      "Epoch 99/100\n",
      "78/78 [==============================] - 41s 529ms/step - loss: 0.4370 - acc: 0.8460 - val_loss: 0.6964 - val_acc: 0.7756\n",
      "Epoch 100/100\n",
      "78/78 [==============================] - 42s 541ms/step - loss: 0.4279 - acc: 0.8540 - val_loss: 0.6927 - val_acc: 0.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4bb41b47b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100, steps_per_epoch=10000//128, validation_steps=10000//128, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(val_dataset.take(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
